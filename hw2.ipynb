{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a91eac5-00f4-4fca-a81e-2d613639f0d0",
   "metadata": {
    "ExecutionIndicator": {
     "show": false
    },
    "execution": {
     "iopub.execute_input": "2025-03-08T02:30:53.645658Z",
     "iopub.status.busy": "2025-03-08T02:30:53.645305Z",
     "iopub.status.idle": "2025-03-08T02:30:53.808238Z",
     "shell.execute_reply": "2025-03-08T02:30:53.807776Z",
     "shell.execute_reply.started": "2025-03-08T02:30:53.645639Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.01629\n",
      "Epoch 100, Loss: 0.01578\n",
      "Epoch 200, Loss: 0.01514\n",
      "Epoch 300, Loss: 0.01429\n",
      "Epoch 400, Loss: 0.01317\n",
      "Epoch 500, Loss: 0.01164\n",
      "Epoch 600, Loss: 0.00958\n",
      "Epoch 700, Loss: 0.00691\n",
      "Epoch 800, Loss: 0.00395\n",
      "Epoch 900, Loss: 0.00159\n",
      "Epoch 1000, Loss: 0.00044\n",
      "Epoch 1100, Loss: 0.00009\n",
      "Epoch 1200, Loss: 0.00002\n",
      "Epoch 1300, Loss: 0.00000\n",
      "Epoch 1400, Loss: 0.00000\n",
      "Epoch 1500, Loss: 0.00000\n",
      "Epoch 1600, Loss: 0.00000\n",
      "Epoch 1700, Loss: 0.00000\n",
      "Epoch 1800, Loss: 0.00000\n",
      "Epoch 1900, Loss: 0.00000\n",
      "\n",
      "Final Loss: 0.00000\n",
      "Final Prediction: 0.80000\n",
      "\n",
      "Final Weights and Biases:\n",
      "w1: [[ 2.00483185  1.00966369]\n",
      " [ 1.0816828  -0.83663441]\n",
      " [ 0.92477578  0.84955156]]\n",
      "b1: [ 2.00966369  1.16336559 -1.15044844]\n",
      "w2: [[ 3.1580082  -0.89306841  1.09334593]\n",
      " [-1.26692501 -2.18100758  1.84267995]\n",
      " [ 0.7128582  -1.19304396  0.82907689]]\n",
      "b2: [-1.8391253   2.72823435 -1.29235703]\n",
      "w3: [-1.50829326  2.44432113  1.74488292]\n",
      "b3: [0.31817271]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function and its derivative\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "# Mean Squared Error (MSE) loss function and its derivative\n",
    "def mse_loss(y_pred, y_true):\n",
    "    return 0.5 * np.sum((y_pred - y_true) ** 2)\n",
    "\n",
    "def mse_loss_derivative(y_pred, y_true):\n",
    "    return y_pred - y_true\n",
    "\n",
    "# Initialize input, weights, and target output\n",
    "x1, x2 = 0.5, 1.0\n",
    "x = np.array([x1, x2], dtype=np.float64)  # Input vector (2,)\n",
    "\n",
    "y_true = np.array([0.8], dtype=np.float64)  # True output value\n",
    "\n",
    "# Initialize weights\n",
    "w1 = np.array([[2.0, 1.0], [1.0, -1.0], [1.0, 1.0]], dtype=np.float64)  # (3,2)\n",
    "b1 = np.array([2.0, 1.0, -1.0], dtype=np.float64)  # (3,)\n",
    "\n",
    "w2 = np.array([[3.0, -1.0, 1.0], [-1.0, -2.0, 2.0], [1.0, -1.0, 1.0]], dtype=np.float64)  # (3,3)\n",
    "b2 = np.array([-2.0, 3.0, -1.0], dtype=np.float64)  # (3,)\n",
    "\n",
    "w3 = np.array([-1.0, 3.0, 2.0], dtype=np.float64)  # (3,)\n",
    "b3 = np.array([1.0], dtype=np.float64)  # (1,)\n",
    "\n",
    "# Hyperparameters\n",
    "learning_rate = 0.1\n",
    "epochs = 2000  # Number of training iterations\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    # Forward propagation\n",
    "    z1 = np.dot(w1, x) + b1  # (3,)\n",
    "    a1 = sigmoid(z1)  # (3,)\n",
    "\n",
    "    z2 = np.dot(w2, a1) + b2  # (3,)\n",
    "    a2 = sigmoid(z2)  # (3,)\n",
    "\n",
    "    z3 = np.dot(w3, a2) + b3  # (1,)\n",
    "    y_pred = sigmoid(z3)  # (1,)\n",
    "\n",
    "    # Compute loss\n",
    "    loss = mse_loss(y_pred, y_true)\n",
    "\n",
    "    # Backward propagation\n",
    "    d_loss = mse_loss_derivative(y_pred, y_true)  # (1,)\n",
    "\n",
    "    d_z3 = d_loss * sigmoid_derivative(z3)  # (1,)\n",
    "    d_w3 = d_z3 * a2  # (3,)\n",
    "    d_b3 = d_z3  # (1,)\n",
    "\n",
    "    d_a2 = w3 * d_z3  # (3,)\n",
    "    d_z2 = d_a2 * sigmoid_derivative(z2)  # (3,)\n",
    "    d_w2 = np.outer(d_z2, a1)  # (3,3)\n",
    "    d_b2 = d_z2  # (3,)\n",
    "\n",
    "    d_a1 = np.dot(w2.T, d_z2)  # (3,)\n",
    "    d_z1 = d_a1 * sigmoid_derivative(z1)  # (3,)\n",
    "    d_w1 = np.outer(d_z1, x)  # (3,2)\n",
    "    d_b1 = d_z1  # (3,)\n",
    "\n",
    "    # Update weights and biases using gradient descent\n",
    "    w1 -= learning_rate * d_w1\n",
    "    b1 -= learning_rate * d_b1\n",
    "    w2 -= learning_rate * d_w2\n",
    "    b2 -= learning_rate * d_b2\n",
    "    w3 -= learning_rate * d_w3\n",
    "    b3 -= learning_rate * d_b3\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.5f}\")\n",
    "\n",
    "# Final output after training\n",
    "print(f\"\\nFinal Loss: {loss:.5f}\")\n",
    "print(f\"Final Prediction: {y_pred[0]:.5f}\")\n",
    "print(\"\\nFinal Weights and Biases:\")\n",
    "print(\"w1:\", w1)\n",
    "print(\"b1:\", b1)\n",
    "print(\"w2:\", w2)\n",
    "print(\"b2:\", b2)\n",
    "print(\"w3:\", w3)\n",
    "print(\"b3:\", b3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72862b11-f347-409a-90d4-f7aac72ec5ca",
   "metadata": {},
   "source": [
    "以上使用了 gpt-4 生成初始代码，并手写 forward and backward propagation 替代了它直接调用的包"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "516d8cf0-7ed5-4aa4-8a3d-3bff4d713a61",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:37:57.083892Z",
     "iopub.status.busy": "2025-03-08T06:37:57.083496Z",
     "iopub.status.idle": "2025-03-08T06:37:57.091288Z",
     "shell.execute_reply": "2025-03-08T06:37:57.090709Z",
     "shell.execute_reply.started": "2025-03-08T06:37:57.083867Z"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.80000319]\n"
     ]
    }
   ],
   "source": [
    "# Verify the results above\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Input\n",
    "X = np.array([0.5, 1])\n",
    "\n",
    "# Weights and biases\n",
    "w1 = np.array([[2.00483185, 1.00966369],\n",
    "               [1.0816828, -0.83663441],\n",
    "               [0.92477578, 0.84955156]])\n",
    "b1 = np.array([ 2.00966369 , 1.16336559, -1.15044844])\n",
    "w2 = np.array([[ 3.1580082 , -0.89306841,  1.09334593],\n",
    "               [-1.26692501, -2.18100758,  1.84267995],\n",
    "               [ 0.7128582 , -1.19304396 , 0.82907689]])\n",
    "b2 = np.array([-1.8391253 ,  2.72823435, -1.29235703])\n",
    "w3 = np.array([-1.50829326 , 2.44432113 , 1.74488292])\n",
    "b3 = np.array([0.31817271])\n",
    "\n",
    "# Calculate output\n",
    "z1 = np.dot(X, w1.T) + b1\n",
    "a1 = sigmoid(z1)\n",
    "\n",
    "z2 = np.dot(a1, w2.T) + b2\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "z3 = np.dot(a2, w3.T) + b3\n",
    "output = sigmoid(z3)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b1f5620-c7d5-4feb-8ab2-8c231fa3f5ba",
   "metadata": {},
   "source": [
    "以上验证 final weights and biases 正确\n",
    "将上面的代码输入 gpt-4 并让它改用pytorch ,debug 完如下："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f97b491f-5474-4bd8-b66c-0509ce11d1dd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:50:13.674259Z",
     "iopub.status.busy": "2025-03-08T06:50:13.673880Z",
     "iopub.status.idle": "2025-03-08T06:50:16.512379Z",
     "shell.execute_reply": "2025-03-08T06:50:16.511868Z",
     "shell.execute_reply.started": "2025-03-08T06:50:13.674236Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 0.18135\n",
      "Epoch 100, Loss: 0.00000\n",
      "Epoch 200, Loss: 0.00000\n",
      "Epoch 300, Loss: 0.00000\n",
      "Epoch 400, Loss: 0.00000\n",
      "Epoch 500, Loss: 0.00000\n",
      "Epoch 600, Loss: 0.00000\n",
      "Epoch 700, Loss: 0.00000\n",
      "Epoch 800, Loss: 0.00000\n",
      "Epoch 900, Loss: 0.00000\n",
      "Epoch 1000, Loss: 0.00000\n",
      "Epoch 1100, Loss: 0.00000\n",
      "Epoch 1200, Loss: 0.00000\n",
      "Epoch 1300, Loss: 0.00000\n",
      "Epoch 1400, Loss: 0.00000\n",
      "Epoch 1500, Loss: 0.00000\n",
      "Epoch 1600, Loss: 0.00000\n",
      "Epoch 1700, Loss: 0.00000\n",
      "Epoch 1800, Loss: 0.00000\n",
      "Epoch 1900, Loss: 0.00000\n",
      "Final Loss: 0.00000\n",
      "Final Prediction: 0.80000\n",
      "\n",
      "Final Weights and Biases:\n",
      "fc1.weight: tensor([[0.4970, 0.5740],\n",
      "        [0.3243, 0.8622],\n",
      "        [0.5269, 1.4981]])\n",
      "fc1.bias: tensor([0.4515, 0.3853, 1.0734])\n",
      "fc2.weight: tensor([[-1.1474, -0.8509, -0.9329],\n",
      "        [ 0.1969,  0.7284,  1.2665],\n",
      "        [ 1.4185,  1.4959,  1.4884]])\n",
      "fc2.bias: tensor([-0.9211,  0.9989,  1.0929])\n",
      "fc3.weight: tensor([[0.4140, 0.5326, 0.8230]])\n",
      "fc3.bias: tensor([0.0506])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define the Neural Network class\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.fc1 = nn.Linear(2, 3)  # Input layer (2) -> Hidden layer 1 (3)\n",
    "        self.fc2 = nn.Linear(3, 3)  # Hidden layer 1 (3) -> Hidden layer 2 (3)\n",
    "        self.fc3 = nn.Linear(3, 1)  # Hidden layer 2 (3) -> Output layer (1)\n",
    "        self.activation = nn.Sigmoid()  # Sigmoid activation function\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.activation(self.fc1(x))\n",
    "        x = self.activation(self.fc2(x))\n",
    "        x = self.activation(self.fc3(x))\n",
    "        return x\n",
    "\n",
    "# Select device (use GPU if available)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Initialize the network\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# Training data\n",
    "x_train = torch.tensor([[0.5, 1.0]], dtype=torch.float32).to(device)  # Input\n",
    "y_train = torch.tensor([[0.8]], dtype=torch.float32).to(device)  # Target output\n",
    "\n",
    "# Loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.1)\n",
    "\n",
    "# Training parameters\n",
    "epochs = 2000\n",
    "\n",
    "# Training loop\n",
    "for epoch in range(epochs):\n",
    "    optimizer.zero_grad()  # Clear gradients\n",
    "    y_pred = model(x_train)  # Forward pass\n",
    "    loss = criterion(y_pred, y_train)  # Compute loss\n",
    "    loss.backward()  # Backpropagation\n",
    "    optimizer.step()  # Update weights\n",
    "\n",
    "    # Print loss every 100 epochs\n",
    "    if epoch % 100 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss.item():.5f}\")\n",
    "\n",
    "# Final results\n",
    "print(f\"Final Loss: {loss.item():.5f}\")\n",
    "print(f\"Final Prediction: {y_pred.item():.5f}\")\n",
    "\n",
    "# Print final weights and biases\n",
    "print(\"\\nFinal Weights and Biases:\")\n",
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.data}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "374b6e88-e3e1-4172-ad74-430e7efab1ec",
   "metadata": {},
   "source": [
    "这个内置的算法收敛速度更快，得到不同的final weights and biases，但也正确。不同的初始值可以得到满足要求的不同final weights and biases。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc0c1d08-2ba7-47b5-a988-3569957e6bfc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-03-08T06:52:49.608849Z",
     "iopub.status.busy": "2025-03-08T06:52:49.608431Z",
     "iopub.status.idle": "2025-03-08T06:52:49.614566Z",
     "shell.execute_reply": "2025-03-08T06:52:49.614080Z",
     "shell.execute_reply.started": "2025-03-08T06:52:49.608829Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.79999391]\n"
     ]
    }
   ],
   "source": [
    "# Verify the results above\n",
    "import numpy as np\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Input\n",
    "X = np.array([0.5, 1])\n",
    "\n",
    "# Weights and biases\n",
    "w1 = np.array([[0.4970, 0.5740],\n",
    "        [0.3243, 0.8622],\n",
    "        [0.5269, 1.4981]])\n",
    "b1 = np.array([0.4515, 0.3853, 1.0734])\n",
    "w2 = np.array([[-1.1474, -0.8509, -0.9329],\n",
    "        [ 0.1969,  0.7284,  1.2665],\n",
    "        [ 1.4185,  1.4959,  1.4884]])\n",
    "b2 = np.array([-0.9211,  0.9989,  1.0929])\n",
    "w3 = np.array([[0.4140, 0.5326, 0.8230]])\n",
    "b3 = np.array([0.0506])\n",
    "\n",
    "# Calculate output\n",
    "z1 = np.dot(X, w1.T) + b1\n",
    "a1 = sigmoid(z1)\n",
    "\n",
    "z2 = np.dot(a1, w2.T) + b2\n",
    "a2 = sigmoid(z2)\n",
    "\n",
    "z3 = np.dot(a2, w3.T) + b3\n",
    "output = sigmoid(z3)\n",
    "\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2571e3a3-fcc3-4501-bdc4-85084c4ee407",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
